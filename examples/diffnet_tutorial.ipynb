{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In general, before running diffnets your directory structure should look something like this... you have a directory that contains simulation data. In that directory you have a directory for each variant that contains all simulations for that given variant. Then, you should have pdb files to go with the trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "practice_dir\n",
    "|\n",
    "|\n",
    " ----->simulation_data\n",
    "         |----->var1\n",
    "               ------sim1.xtc\n",
    "               ------sim2.xtc\n",
    "               ------sim3.xtc\n",
    "         |----->var2\n",
    "               ------sim1.xtc\n",
    "               ------sim2.xtc\n",
    "               ------sim3.xtc\n",
    "          |var1.pdb\n",
    "          |var2.pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, copy the diffnets **diffnets/tests/data** to a new directory to practice running diffnets. This dataset only contains two variants and they each have one trajectory so your setup should look something like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "practice_dir\n",
    "|\n",
    "|\n",
    " ----->data\n",
    "         |----->traj1\n",
    "               ------beta-peptide1.xtc\n",
    "         |----->var2\n",
    "               ------beta-peptide2.xtc\n",
    "         |beta-peptide1.pdb\n",
    "         |beta-peptide2.pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, cd into your practice dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mickdub/bowman_lab/scratch/practice_dir\n"
     ]
    }
   ],
   "source": [
    "cd practice_dir/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we need to preprocess this simulation data to turn it into DiffNet input\n",
    "-- Ultimately, we want to do that through the command line interface (CLI) which looks like this...\n",
    "\n",
    "**python /path/to/diffnets/diffnets/cli/main.py process {sim_dirs} {pdb_fns} {outdir}**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_dirs = np.array([\"./data/traj1/\",\n",
    "            \"./data/traj2/\"])\n",
    "np.save(\"./traj_dirs.npy\",sim_dirs)\n",
    "\n",
    "pdb_fns = np.array([\"./data/beta-peptide1.pdb\",\n",
    "                    \"./data/beta-peptide2.pdb\"])\n",
    "np.save(\"./pdb_fns.npy\",pdb_fns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that the order of **sim_dirs** and **pdb_fns** matters and the pdb order has to correspond to the trajectory order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, our directory looks something like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "practice_dir\n",
    "  |\n",
    "  |pdb_fns.npy\n",
    "  |traj_dirs.npy\n",
    "  |\n",
    "   ----->data\n",
    "         |----->traj1\n",
    "               ------beta-peptide1.xtc\n",
    "         |----->var2\n",
    "               ------beta-peptide2.xtc\n",
    "         |beta-peptide1.pdb\n",
    "         |beta-peptide2.pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to run the data processing step! You should run this next step at the command line (outside of this notebook). Submit this to a CPU node on a cluster and request as many cores as are available on that node.\n",
    "\n",
    "**python /path/to/diffnets/diffnets/cli/main.py process ./traj_dirs.npy ./pdb_fns.npy ./whitened_data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, your directory should look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "practice_dir\n",
    "  |pdb_fns.npy\n",
    "  |traj_dirs.npy\n",
    "  |\n",
    "   ----->data\n",
    "           ----->traj1\n",
    "                   |beta-peptide1.xtc\n",
    "           ----->var2\n",
    "                   |beta-peptide2.xtc\n",
    "           |beta-peptide1.pdb\n",
    "           |beta-peptide2.pdb\n",
    "           |\n",
    "   ----->whitened_data\n",
    "           ----->indicators\n",
    "                   |000000.npy\n",
    "                   |000001.npy\n",
    "           ----->data\n",
    "                   |5001 .pt files (one for each simulation frame)\n",
    "           ----->aligned_xtcs\n",
    "                   |000000.xtc\n",
    "                   |000001.xtc\n",
    "           ----->whitened_xtcs\n",
    "           |master.pdb\n",
    "           |traj_dict.pkl\n",
    "           |traj_lens.npy\n",
    "           |cm.npy\n",
    "           |c00.npy\n",
    "           |uwm.npy\n",
    "           |wm.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have added a \"whitened_data\" directory that contains the following:\n",
    "\n",
    "--an **aligned_xtcs** dir: one .xtc file for each trajectory where the trajectory has been stripped to (C,CA,CB,N) atoms and aligned to the first pdb supplied in pdb_fns (beta-peptide1.pdb). To change what atom selection you want to use, you can optionally supply {atom_sel} to the CLI command that generated this data. See the preprocess_data function in cli/main.py for more details.\n",
    "\n",
    "--an **indicators** dir: one .npy file for each trajectory where the numbering matches the numbering in aligned_xtcs. The file is a numpy array that has as many values as simulation frames and indicates which variant the trajectory is of. It is zero-indexed so in our case, a value of 0 indicates var1 and a value of 1 indicates var2.\n",
    "\n",
    "--a **data** dir: one .pt file (pytorch tensor) for each simulation frame. Lots of data means lots of files here.\n",
    "\n",
    "--master.pdb: The stripped pdb (C,CA,CB,N) containing the set of atoms that is common to all variants. \n",
    "\n",
    "--traj_dict.pkl: Helper for plotting later (see Analysis.assign_labels_to_variants in analysis.py for more info).\n",
    "\n",
    "--cm.npy: center of mass calculated from ALL simulation frames.\n",
    "\n",
    "--c00.npy: covariance matrix calculated from ALL simulation frames. \n",
    "\n",
    "--wm.npy: whitening matrix which will be used as a layer in the DiffNet.\n",
    "\n",
    "--uwm.npy: unwhitening matrix which will be used as a layer in the DiffNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, we will train the diffnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, we want to run this command:\n",
    "    \n",
    "**python /path/to/diffnets/diffnets/cli/main.py train config.yml**\n",
    "\n",
    "take a look at an example config.yml file at docs/train_sample.yml, but I will also display it here.\n",
    "\n",
    "Remember, we are still cd'd into practice_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir: './whitened_data'\n",
    "n_epochs: 10 #How many times do we want to go through the training data?\n",
    "act_map: [0,1] #initial label for var1 is 0 and for var2 its 1. \n",
    "               #Important note, if we had 4 variants (var1, var2, var3, var4) and we wanted to distingusih\n",
    "               #var1,var2 from var3, var4 act_map would look like [0,0,1,1].\n",
    "               #The order follows the order we originally put in pdb_fns.npy\n",
    "lr: 0.0001\n",
    "n_latent: 50 #Number of dimensions to reduce the data down to.\n",
    "hidden_layer_sizes: [] #Leave blank array [] for default of 1 hidden layer\n",
    "                       #that has 4x less nodes than input.\n",
    "em_bounds: [[0.1,0.4],[0.6,0.9]] #one bound for each variant -- these are reasonable default values\n",
    "do_em: True\n",
    "em_batch_size: 150\n",
    "nntype: 'nnutils.sae' #one of several architectures that can be used, the other\n",
    "                      #common choice would be nnutils.split_sae.\n",
    "                      #nnutils.sae classifies based on the entire protein structure\n",
    "                      #nnutils.split_sae can classify (find differences) based on a specific region\n",
    "                      #of the structure. For nnutils.split_sae you will have to supply indices via the\n",
    "                      #close_inds_fn option described below.\n",
    "batch_size: 32\n",
    "batch_output_freq: 500\n",
    "epoch_output_freq: 2\n",
    "test_batch_size: 1000\n",
    "frac_test: 0.1\n",
    "subsample: 1  #You can subsample the data during training. Recommended if training on huge datasets. \n",
    "outdir: 'sae_e10_lr0001_lat50_rep0_em' #training will create an output directory. Name it however you like\n",
    "                                       #just make sure a dir with the same name doesn't already exist\n",
    "data_in_mem: False  #For small datasets, you can load all the data into memory at once\n",
    "#close_inds_fn: close_inds.npy #Only necessary if using a split autoencoder. np.array of the atom indices that go into classification task. See train_sample.txt.\n",
    "#label_spreading: 'gaussian' #Optional parameter to draw initial labels from a normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now your directory should look something like this -- for the sake of brevity the contents of the newly added dir are not exactly as you might see them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "practice_dir\n",
    "  |pdb_fns.npy\n",
    "  |traj_dirs.npy\n",
    "  |\n",
    "   ----->data\n",
    "           ----->traj1\n",
    "                   |beta-peptide1.xtc\n",
    "           ----->var2\n",
    "                   |beta-peptide2.xtc\n",
    "           |beta-peptide1.pdb\n",
    "           |beta-peptide2.pdb\n",
    "           |\n",
    "   ----->whitened_data\n",
    "           ----->indicators\n",
    "                   |000000.npy\n",
    "                   |000001.npy\n",
    "           ----->data\n",
    "                   |5001 .pt files (one for each simulation frame)\n",
    "           ----->aligned_xtcs\n",
    "                   |000000.xtc\n",
    "                   |000001.xtc\n",
    "           ----->whitened_xtcs\n",
    "           |master.pdb\n",
    "           |traj_dict.pkl\n",
    "           |traj_lens.npy\n",
    "           |cm.npy\n",
    "           |c00.npy\n",
    "           |uwm.npy\n",
    "           |wm.npy\n",
    "   ----->sae_e10_lr0001_lat50_rep0_em\n",
    "           |nn_best_polish.pkl + many other pkl files of intermediate networks saved\n",
    "           |tmp_targets.npy\n",
    "           |training_loss.npy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your new dir **sae_e10_lr0001_lat50_rep0_em** you have trained diffnets (e.g. nn_best_polish.pkl) and some other data that is not a major concern to explore right now. Just make sure you have nn_best_polish.pkl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, we can simply run this command line command:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**python /path/to/diffnets/diffnets/cli/main.py analyze ./whitened_data ./sae_e10_lr0001_lat50_rep0_em**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, your directory structure will look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "practice_dir\n",
    "  |pdb_fns.npy\n",
    "  |traj_dirs.npy\n",
    "  |\n",
    "   ----->data\n",
    "           ----->traj1\n",
    "                   |beta-peptide1.xtc\n",
    "           ----->var2\n",
    "                   |beta-peptide2.xtc\n",
    "           |beta-peptide1.pdb\n",
    "           |beta-peptide2.pdb\n",
    "           |\n",
    "   ----->whitened_data\n",
    "           ----->indicators\n",
    "                   |000000.npy\n",
    "                   |000001.npy\n",
    "           ----->data\n",
    "                   |5001 .pt files (one for each simulation frame)\n",
    "           ----->aligned_xtcs\n",
    "                   |000000.xtc\n",
    "                   |000001.xtc\n",
    "           ----->whitened_xtcs\n",
    "           |master.pdb\n",
    "           |traj_dict.pkl\n",
    "           |traj_lens.npy\n",
    "           |cm.npy\n",
    "           |c00.npy\n",
    "           |uwm.npy\n",
    "           |wm.npy\n",
    "   ----->sae_e10_lr0001_lat50_rep0_em\n",
    "           ----->encodings\n",
    "                   |000000.npy\n",
    "                   |000001.npy\n",
    "           ----->labels\n",
    "                   |000000.npy\n",
    "                   |000001.npy\n",
    "           ----->recon_trajs\n",
    "                   |000000.xtc\n",
    "                   |000001.xtc\n",
    "           ----->morph_label\n",
    "                   |morph_0-1.pdb\n",
    "           ----->cluster_1000\n",
    "                   |clusters.pkl\n",
    "           |rmsd.npy\n",
    "           |res-corr100.pml\n",
    "           |nn_best_polish.pkl + many other pkl files of intermediate networks saved\n",
    "           |tmp_targets.npy\n",
    "           |training_loss.npy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**recon_trajs**: each trajectory gets reconstructed by the DiffNets and an rmsd to the original trajectories is calculated for every 100th frame (**rmsd.npy**)\n",
    "\n",
    "**labels**: each trajectory has a .npy file where the numpy array contains a DiffNet classification label for each frame\n",
    "\n",
    "**encodings**: each trajectory has a .npy file where the numpy array contains the latent vector for each frame (i.e. your reduced dimensionality representation)\n",
    "\n",
    "**morph_label**: A pdb containing 10 representative states morphing from a DiffNet classification label of 0 to 1\n",
    "\n",
    "**cluster_1000**: A k-centers/k-medoids hybrid clustering using the DiffNet latent space\n",
    "\n",
    "**res-corr100.pml**: Load whitened_data/master.pdb into pymol, then load this pml file in to get an image like Figure 7 in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
